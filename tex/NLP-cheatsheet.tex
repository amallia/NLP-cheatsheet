\documentclass[10pt,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}

% To make this come out properly in landscape mode, do one of the following
% 1.
%  pdflatex latexsheet.tex
%
% 2.
%  latex latexsheet.tex
%  dvips -P pdf  -t landscape latexsheet.dvi
%  ps2pdf latexsheet.ps


% If you're reading this, be prepared for confusion.  Making this was
% a learning experience for me, and it shows.  Much of the placement
% was hacked in; if you make it better, let me know...


% 2008-04
% Changed page margin code to use the geometry package. Also added code for
% conditional page margins, depending on paper size. Thanks to Uwe Ziegenhagen
% for the suggestions.

% 2006-08
% Made changes based on suggestions from Gene Cooperman. <gene at ccs.neu.edu>


% To Do:
% \listoffigures \listoftables
% \setcounter{secnumdepth}{0}


% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
	{ \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}

% Turn off header and footer
\pagestyle{empty}
 

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}


% -----------------------------------------------------------------------

\begin{document}

\raggedright
\footnotesize
\begin{multicols}{3}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\begin{center}
     \Large{\textbf{NLP Cheat Sheet}} \\
\end{center}

\section{Bag of Words Methods}
\subsection{Information Retrieval}
\subsubsection{Cosine similarity metric}
Define a similarity metric between topic vectors. It is the cosine of the 
angle between the term vectors.

\begin{equation*}
sim(A, B) = \frac{\sum_{i} a_i \times b_i}{\sqrt{\sum_{i} a_i^2} \times \sqrt{\sum_{i} b_i^2}}
\end{equation*}

Unusual words determine the topic much more than common words.
Weight each term frequency $tf_i$ by its inverse document frequency $idf$.
\begin{equation*}
idf_i = \log (\frac{N}{n_i})
\end{equation*}

where $N$=size of collection and $n_i$ = number of documents containing term  $i$
\begin{equation*}
w_i = tf_i \times idf_i
\end{equation*}

\resizebox{\textwidth/3}{!}{ 
$sim(A, B) = \frac{\sum_{w \in A,B} tf_{w,A} \times tf_{w,B} \times idf_w^2}{\sqrt{\sum_{w_1 \in A} (tf_{w_1,A} idf_{w_1})^2} \times \sqrt{\sum_{w_2 \in B} (tf_{w_2,A} idf_{w_2})^2}}$
}

\subsection{Sentiment analysis (opinion mining)}

Opinion mining is the task of judging whether a document expresses a positive or a negative opinion (or no opinion) regarding a particular object or topic. 

The simplest strategy uses a bag-of-words model. We create lists of 'positive' and 'negative' words and judge a document based on whether it has a preponderance of positive or negative words (and judge it neutral or 'objective' if it has few words of either category.

Creating such lists is not easy; some of the words are likely to be quite different for different kinds of topics. As an alternative, we will take a collection of documents on some topic and rate them (by hand) as positive or negative. We will then use this collection to train a classifier model.




\rule{0.3\linewidth}{0.25pt}
\scriptsize

Copyright \copyright\ 2018 Antonio Mallia

\href{https://www.antoniomallia.it}{https://www.antoniomallia.it}


\end{multicols}
\end{document}
